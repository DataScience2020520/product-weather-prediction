{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyspark\n",
    "from functools import reduce\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import desc,asc, monotonically_increasing_id, split, size, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_day(start_day):\n",
    "  import datetime\n",
    "  date_arr = start_day.split(\"/\")\n",
    "  end_date =  datetime.datetime(int('20' +date_arr[2]), int(date_arr[0]), int(date_arr[1]))    \n",
    "  start_date = end_date + datetime.timedelta(days=-20)\n",
    "  return start_date.strftime(\"%Y%m%d\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StructType\n",
    "get_start_day_udf = udf(get_start_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_end_day(start_day):\n",
    "  import datetime\n",
    "  date_arr = start_day.split(\"/\")\n",
    "  end_date =  datetime.datetime(int('20' +date_arr[2]), int(date_arr[0]), int(date_arr[1]))    \n",
    "  start_date = end_date + datetime.timedelta(days=-20)\n",
    "  return end_date.strftime(\"%Y%m%d\")\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StructType\n",
    "get_end_day_udf = udf(get_end_day)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "def get_average( array):\n",
    "  return mean(array)\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StructType\n",
    "get_average_udf = udf(get_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_plot(col, df):\n",
    "  col_series = df.groupBy(col).count().sort(desc(\"count\"))\n",
    "  total_sum = col_series.agg({\"count\":\"sum\"}).collect()[0][0]\n",
    "  col_series = col_series.withColumn('variances', udf(lambda x: int(x)/total_sum)('count'))\n",
    "  windowval = (Window.orderBy(F.col('count').desc()).rangeBetween(Window.unboundedPreceding, 0))\n",
    "  col_series = col_series.withColumn('cum_sum', F.sum('variances').over(windowval))\n",
    "  plt.plot(col_series.select('cum_sum').collect())\n",
    "  display(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(df):\n",
    "   \n",
    "    # Total missing values\n",
    "    mis_val = df.isnull().sum()\n",
    "    \n",
    "    # Percentage of missing values\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "    \n",
    "    # Make a table with the results\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "    \n",
    "    # Rename the columns\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "    \n",
    "    # Sort the table by percentage of missing descending\n",
    "    # .iloc[:, 1]!= 0: filter on missing missing values not equal to zero\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "    '% of Total Values', ascending=False).round(2)  # round(2), keep 2 digits\n",
    "    \n",
    "    # Print some summary information\n",
    "    print(\"Your slelected dataframe has {} columns.\".format(df.shape[1]) + '\\n' + \n",
    "    \"There are {} columns that have missing values.\".format(mis_val_table_ren_columns.shape[0]))\n",
    "    \n",
    "    # Return the dataframe with missing information\n",
    "    return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_plot(col, df):\n",
    "  col_series = df.groupBy(col).count().sort(desc(\"count\"))\n",
    "  total_sum = col_series.agg({\"count\":\"sum\"}).collect()[0][0]\n",
    "  col_series = col_series.withColumn('variances', udf(lambda x: int(x)/total_sum)('count'))\n",
    "  windowval = (Window.orderBy(F.col('count').desc()).rangeBetween(Window.unboundedPreceding, 0))\n",
    "  col_series = col_series.withColumn('cum_sum', F.sum('variances').over(windowval))\n",
    "  plt.plot(col_series.select('cum_sum').collect())\n",
    "  display(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_values(n, col, df):\n",
    "  col_series = df.groupBy(col).count().sort(desc(\"count\"))\n",
    "  vals = col_series.filter(~F.col(col).isin('nan','')).head(n) ##number 20 should be n\n",
    "  final_values = [x[0] for x in vals]\n",
    "  return final_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varianceplot_nvalue(col, df):\n",
    "  col_series = df.groupBy(col).count().sort(desc(\"count\"))\n",
    "  total_sum = col_series.agg({\"count\":\"sum\"}).collect()[0][0]\n",
    "  col_series = col_series.withColumn('variances', udf(lambda x: int(x)/total_sum)('count'))\n",
    "  windowval = (Window.orderBy(F.col('count').desc()).rangeBetween(Window.unboundedPreceding, 0))\n",
    "  col_series = col_series.withColumn('cum_sum', F.sum('variances').over(windowval))\n",
    "  n = col_series.filter(F.col('cum_sum') <= 0.98).count() \n",
    "  plt.plot(col_series.select('cum_sum').collect())\n",
    "  return plt.show(), n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_col_values(val):\n",
    "    result = val if val in final_values else ''\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
